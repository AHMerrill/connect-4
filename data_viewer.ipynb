{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect4 dataset viewer\n",
    "\n",
    "This notebook documents the two datasets in `final_data/`:\n",
    "\n",
    "- `vanilla_mcts.npz`: dataset generated from vanilla MCTS.\n",
    "- `guided_mcts.npz`: dataset generated from CNN-guided MCTS.\n",
    "\n",
    "Each dataset contains:\n",
    "\n",
    "- `boards`: 6x7 grid with +1 (to-move), -1 (opponent), 0 (empty)\n",
    "- `X`: 6x7x2 encoding (channel 0 = to-move, channel 1 = opponent)\n",
    "- `visits`: raw MCTS visit counts per column (length 7)\n",
    "- `scores`: raw MCTS net scores per column (length 7)\n",
    "- `policy`: normalized visits (length 7)\n",
    "- `q`: per-move expected outcome (length 7)\n",
    "- `value`: expected outcome for the board (length 1)\n",
    "\n",
    "We will load the files, inspect shapes, show full examples with visual boards,\n",
    "show how to mirror a dataset, and describe how to train and run a two-headed\n",
    "policy/value CNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources (tunables)\n",
    "\n",
    "Update these paths/URLs when your data moves (local file paths or GitHub release links).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import tempfile\n",
    "\n",
    "# Data sources can be local paths OR direct URLs to .npz files.\n",
    "VANILLA_NPZ = \"vanilla_mcts.npz\"\n",
    "GUIDED_NPZ = \"guided_mcts.npz\"\n",
    "\n",
    "# Example GitHub release URLs (update as needed):\n",
    "# VANILLA_NPZ = \"https://github.com/AHMerrill/connect-4/releases/download/v0.1-data/vanilla_mcts_not_mirrored_200_3000.npz\"\n",
    "# GUIDED_NPZ = \"https://github.com/AHMerrill/connect-4/releases/download/v0.1-data/guided_mcts_mirrored_500_3000.npz\"\n",
    "\n",
    "\n",
    "def load_npz(source):\n",
    "    # Load from local path or download URL to a temp file.\n",
    "    if str(source).startswith(\"http://\") or str(source).startswith(\"https://\"):\n",
    "        tmp_dir = Path(tempfile.gettempdir())\n",
    "        tmp_path = tmp_dir / Path(str(source)).name\n",
    "        if not tmp_path.exists():\n",
    "            urllib.request.urlretrieve(str(source), tmp_path)\n",
    "        return np.load(tmp_path)\n",
    "    return np.load(Path(source))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "\n",
    "This block loads the two `.npz` files and stores them in a dictionary so we can\n",
    "reference them consistently. We keep the paths explicit to avoid accidental\n",
    "mixups.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load datasets using the tunables above.\n",
    "npz = {\n",
    "    \"vanilla\": load_npz(VANILLA_NPZ),\n",
    "    \"guided\": load_npz(GUIDED_NPZ),\n",
    "}\n",
    "print(\"Loaded vanilla:\", VANILLA_NPZ)\n",
    "print(\"Loaded guided:\", GUIDED_NPZ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick dataset summary\n",
    "\n",
    "This block prints the number of boards and the shapes of each stored array. It is\n",
    "useful for confirming that all required fields are present and consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, data in npz.items():\n",
    "    print(\"\n",
    "Dataset:\", name)\n",
    "    print(\"boards:\", data[\"boards\"].shape)\n",
    "    print(\"X:\", data[\"X\"].shape)\n",
    "    print(\"visits:\", data[\"visits\"].shape)\n",
    "    print(\"scores:\", data[\"scores\"].shape)\n",
    "    print(\"policy:\", data[\"policy\"].shape)\n",
    "    print(\"q:\", data[\"q\"].shape)\n",
    "    print(\"value:\", data[\"value\"].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a board\n",
    "\n",
    "We render the 6x7 board so it is easy to see where the current player (+1) and\n",
    "opponent (-1) pieces are. This is purely a visualization helper; it does not\n",
    "change any data.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_board(board, title=None):\n",
    "    # Map: -1 (opponent) -> red, 0 -> white, +1 (to-move) -> blue.\n",
    "    cmap = plt.cm.get_cmap(\"bwr\", 3)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(board, cmap=cmap, vmin=-1, vmax=1)\n",
    "    plt.xticks(range(7))\n",
    "    plt.yticks(range(6))\n",
    "    plt.grid(True, color=\"black\", linewidth=0.5)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full random examples (three from each dataset)\n",
    "\n",
    "This block prints **everything** for three random rows from each dataset:\n",
    "\n",
    "- `board` (raw 6x7)\n",
    "- `X` shape and channel sums\n",
    "- `visits`, `scores`, `policy`, `q`, `value`\n",
    "- A visual board plot\n",
    "\n",
    "This is a sanity check that the data is internally consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(7)\n",
    "\n",
    "for name, data in npz.items():\n",
    "    print(\"\n",
    "=== Random samples from\", name, \"===\")\n",
    "    n = data[\"boards\"].shape[0]\n",
    "    for i in range(3):\n",
    "        idx = int(rng.integers(0, n))\n",
    "        board = data[\"boards\"][idx]\n",
    "        X = data[\"X\"][idx]\n",
    "        visits = data[\"visits\"][idx]\n",
    "        scores = data[\"scores\"][idx]\n",
    "        policy = data[\"policy\"][idx]\n",
    "        q = data[\"q\"][idx]\n",
    "        value = data[\"value\"][idx]\n",
    "\n",
    "        print(f\"\n",
    "Sample {i+1} (index {idx})\")\n",
    "        print(\"board:\n",
    "\", board)\n",
    "        print(\"X shape:\", X.shape)\n",
    "        print(\"X channel0 sum:\", float(X[:, :, 0].sum()), \"channel1 sum:\", float(X[:, :, 1].sum()))\n",
    "        print(\"visits:\", visits)\n",
    "        print(\"scores:\", scores)\n",
    "        print(\"policy:\", policy)\n",
    "        print(\"q:\", q)\n",
    "        print(\"value:\", value)\n",
    "\n",
    "        plot_board(board, title=f\"{name} sample {i+1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mirror a dataset (for symmetry augmentation)\n",
    "\n",
    "This block shows how to mirror boards left-to-right and merge duplicates.\n",
    "\n",
    "- Boards are mirrored by flipping columns.\n",
    "- Policy, visits, and scores are mirrored by reversing the 7-column vectors.\n",
    "- When a mirrored board already exists, we **merge** by summing visits/scores\n",
    "  and averaging policy/value.\n",
    "\n",
    "This produces a symmetry-augmented dataset without changing the meaning of the\n",
    "labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mirror_dataset(data):\n",
    "    boards = data[\"boards\"]\n",
    "    X = data[\"X\"]\n",
    "    policy = data[\"policy\"]\n",
    "    visits = data[\"visits\"]\n",
    "    scores = data[\"scores\"]\n",
    "    value = data[\"value\"]\n",
    "\n",
    "    merged = {}\n",
    "\n",
    "    def add_entry(b, x, p, v, sc, val):\n",
    "        key = tuple(b.ravel())\n",
    "        if key not in merged:\n",
    "            merged[key] = {\n",
    "                \"board\": b,\n",
    "                \"X\": x,\n",
    "                \"policy_sum\": p.copy(),\n",
    "                \"visits_sum\": v.copy(),\n",
    "                \"scores_sum\": sc.copy(),\n",
    "                \"value_sum\": val.copy(),\n",
    "                \"count\": 1,\n",
    "            }\n",
    "            return\n",
    "        merged[key][\"policy_sum\"] += p\n",
    "        merged[key][\"visits_sum\"] += v\n",
    "        merged[key][\"scores_sum\"] += sc\n",
    "        merged[key][\"value_sum\"] += val\n",
    "        merged[key][\"count\"] += 1\n",
    "\n",
    "    for i in range(boards.shape[0]):\n",
    "        b = boards[i]\n",
    "        add_entry(b, X[i], policy[i], visits[i], scores[i], value[i])\n",
    "\n",
    "        b_m = b[:, ::-1]\n",
    "        x_m = X[i][:, ::-1, :]\n",
    "        p_m = policy[i][::-1]\n",
    "        v_m = visits[i][::-1]\n",
    "        s_m = scores[i][::-1]\n",
    "        add_entry(b_m, x_m, p_m, v_m, s_m, value[i])\n",
    "\n",
    "    new_X = np.stack([v[\"X\"] for v in merged.values()], axis=0)\n",
    "    new_policy = np.stack([v[\"policy_sum\"] / v[\"count\"] for v in merged.values()], axis=0)\n",
    "    new_visits = np.stack([v[\"visits_sum\"] for v in merged.values()], axis=0)\n",
    "    new_scores = np.stack([v[\"scores_sum\"] for v in merged.values()], axis=0)\n",
    "    new_value = np.stack([v[\"value_sum\"] / v[\"count\"] for v in merged.values()], axis=0)\n",
    "\n",
    "    print(\"Original boards:\", boards.shape[0])\n",
    "    print(\"Mirrored/merged boards:\", new_X.shape[0])\n",
    "    return {\n",
    "        \"X\": new_X,\n",
    "        \"policy\": new_policy,\n",
    "        \"visits\": new_visits,\n",
    "        \"scores\": new_scores,\n",
    "        \"value\": new_value,\n",
    "    }\n",
    "\n",
    "# Example: mirror the vanilla dataset in memory.\n",
    "mirrored_vanilla = mirror_dataset(npz[\"vanilla\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a two-headed CNN (policy + value)\n",
    "\n",
    "Below is a minimal training skeleton for a two-headed model:\n",
    "\n",
    "- The policy head predicts the move distribution (softmax, 7 outputs).\n",
    "- The value head predicts the expected outcome (tanh, 1 output).\n",
    "\n",
    "In practice, you should also use train/validation splits, learning rate schedules,\n",
    "regularization, and early stopping. This example is a compact reference, not a\n",
    "full training pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example: use the guided dataset for training.\n",
    "X = npz[\"guided\"][\"X\"].astype(np.float32)\n",
    "policy = npz[\"guided\"][\"policy\"].astype(np.float32)\n",
    "value = npz[\"guided\"][\"value\"].astype(np.float32)\n",
    "\n",
    "# Simple train/validation split.\n",
    "rng = np.random.default_rng(7)\n",
    "idx = rng.permutation(X.shape[0])\n",
    "split = int(0.8 * X.shape[0])\n",
    "train_idx, test_idx = idx[:split], idx[split:]\n",
    "\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "policy_train, policy_test = policy[train_idx], policy[test_idx]\n",
    "value_train, value_test = value[train_idx], value[test_idx]\n",
    "\n",
    "inputs = tf.keras.Input(shape=(6, 7, 2), name=\"board_input\")\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "p = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "policy_out = tf.keras.layers.Dense(7, activation=\"softmax\", name=\"policy_output\")(p)\n",
    "\n",
    "v = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "value_out = tf.keras.layers.Dense(1, activation=\"tanh\", name=\"value_output\")(v)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=[policy_out, value_out])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
    "    loss={\"policy_output\": \"categorical_crossentropy\", \"value_output\": \"mse\"},\n",
    "    metrics={\"policy_output\": [\"accuracy\"], \"value_output\": [\"mse\"]},\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    {\"policy_output\": policy_train, \"value_output\": value_train},\n",
    "    validation_data=(X_test, {\"policy_output\": policy_test, \"value_output\": value_test}),\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference example (policy + value)\n",
    "\n",
    "This block shows how to use a trained model for inference on a single board:\n",
    "\n",
    "- Build a board in +1/-1/0 format.\n",
    "- Encode it into 6x7x2.\n",
    "- Run the model to get policy and value.\n",
    "- Mask illegal moves and pick the best column.\n",
    "\n",
    "This is the basic building block for guided MCTS.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example board (replace with an actual position).\n",
    "board = np.zeros((6, 7), dtype=np.int8)\n",
    "board[5, 3] = 1\n",
    "board[5, 2] = -1\n",
    "\n",
    "# Encode and run inference.\n",
    "x = np.stack([(board == 1).astype(np.float32), (board == -1).astype(np.float32)], axis=-1)\n",
    "policy_pred, value_pred = model.predict(x[None, ...], verbose=0)\n",
    "policy = policy_pred[0]\n",
    "value = float(value_pred[0][0])\n",
    "\n",
    "# Mask illegal moves.\n",
    "legal = [i for i in range(7) if abs(board[0, i]) < 0.1]\n",
    "masked = np.full_like(policy, -1e9)\n",
    "masked[legal] = policy[legal]\n",
    "move = int(np.argmax(masked))\n",
    "\n",
    "print(\"Predicted policy:\", policy)\n",
    "print(\"Predicted value:\", value)\n",
    "print(\"Chosen move:\", move)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (workbench)",
   "language": "python",
   "name": "workbench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}